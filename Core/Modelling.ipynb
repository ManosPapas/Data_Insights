{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Make notebooks expand 100%.\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method gives a plot with the distribution of monthly sales, sales and year sold houses.\n",
    "# Parameters \n",
    "# model (Model) : The model we want to use.\n",
    "# parameters (List) : List of parameters for the model.\n",
    "# X_train_ (Array) : Array with values.\n",
    "# y_train_ (Array) : Array with values.\n",
    "# X_valid_ (Array) : Array with values.\n",
    "# y_valid_ (Array) : Array with values.\n",
    "# score_type (String) : Score type.\n",
    "# verbose_ (Boolean) : Verbose or not.\n",
    "# cv_ (Integer) : Number of folds.\n",
    "# Returns : Best model, the best score, best estimator, RMSE and the mean of validation score.\n",
    "def model_results(model, parameters, X_train_, y_train_, X_valid_, y_valid_, score_type='r2', verbose_=False, cv_=10):    \n",
    "    grid = GridSearchCV(model, parameters, verbose=verbose_, scoring=score_type, n_jobs=-1)\n",
    "    \n",
    "    grid.fit(X_train_, y_train_)\n",
    "    \n",
    "    grid.best_estimator_.fit(X_train_, y_train_)\n",
    "    \n",
    "    prediction = grid.best_estimator_.predict(X_valid_)\n",
    "     \n",
    "    RMSE = np.sqrt(mean_squared_error(y_valid_, prediction))\n",
    "    \n",
    "    validation_score = cross_val_score(grid.best_estimator_, X_train_, y_train_, cv=cv_, scoring=score_type)    \n",
    "    \n",
    "    print(\"Best Model: \" + str(grid.best_estimator_) +\n",
    "          \"\\n Best Score: \" + str(grid.best_score_) +\n",
    "          \"\\n RMSE Score: \" + str(RMSE) + \n",
    "          \"\\n Cross Validation Score: \" + str(np.mean(validation_score))\n",
    "         )\n",
    "       \n",
    "    return(grid, grid.best_estimator_, grid.best_score_, RMSE, np.mean(validation_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method gives a plot with the distribution of monthly sales, sales and year sold houses.\n",
    "# Parameters \n",
    "# model (Model) : The model we want to use.\n",
    "# parameters (List) : List of parameters for the model.\n",
    "# X_train_ (Array) : Array with values.\n",
    "# y_train_ (Array) : Array with values.\n",
    "# X_valid_ (Array) : Array with values.\n",
    "# y_valid_ (Array) : Array with values.\n",
    "# train_color_ (String) : The color for the train values.\n",
    "# test_color_ (String) : The color for the test values.\n",
    "# line_color_ (String) : The color for the line.\n",
    "# Returns : The residual plot.\n",
    "def plot_residuals(model, X_train_, y_train_, X_valid_, y_valid_, train_color_='#9999ff', test_color_='r', line_color_='#000000'):    \n",
    "    visualizer = ResidualsPlot(model, train_color=train_color_, test_color=test_color_, line_color=line_color_)\n",
    "    \n",
    "    visualizer.fit(X_train_, y_train_)\n",
    "    \n",
    "    visualizer.score(X_valid_, y_valid_)\n",
    "    \n",
    "    plot = visualizer.poof(outpath=\"residual_plot\")\n",
    "    \n",
    "    return(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method calculates the cumsum of the PCA.\n",
    "# Parameters\n",
    "# df (Dataframe) : The data frame we want to use.\n",
    "# Returns : The cumsum of the PCA.\n",
    "def caluclate_cumsum(df):\n",
    "    pca = PCA()\n",
    "    \n",
    "    X_proj = pca.fit_transform(df)\n",
    "    \n",
    "    pca.fit(df)\n",
    "    \n",
    "    variance = pd.DataFrame(pca.explained_variance_ratio_)\n",
    "    \n",
    "    return(np.cumsum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method plots PCA.\n",
    "# Parameters\n",
    "# df (Dataframe) : The data frame we want to use.\n",
    "# y (Array) : The target variable.\n",
    "# Returns : The plot of the PCA.\n",
    "def plot_pca(df, y):    \n",
    "    X_temp = PCA().fit_transform(df)\n",
    "    \n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(y)))\n",
    "    \n",
    "    plt.scatter(X_temp[:,0], X_temp[:,1],c=colors)\n",
    "    \n",
    "    return(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method plots the variance of the PCA.\n",
    "# Parameters\n",
    "# df (Dataframe) : The data frame we want to use.\n",
    "# Returns : The plot with the variance of the PCA.\n",
    "def plot_pca_variance(df):\n",
    "    pca_dp = PCA().fit(df)\n",
    "    \n",
    "    plt.semilogx(np.cumsum(pca_dp.explained_variance_ratio_))\n",
    "    \n",
    "    plt.xlabel('Number of Components')\n",
    "    \n",
    "    plt.ylabel('Variance retained')\n",
    "    \n",
    "    return(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produces a confusion metric.\n",
    "# Parameters\n",
    "# X (Dataframe) : The predictors.\n",
    "# y (Array) : The prediction column.\n",
    "# Returns : The confusion metric.\n",
    "def metrics_confusion(model, X, y):    \n",
    "    model.fit(X, y)\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    \n",
    "    print(\"Model: \" + str(type(model)))\n",
    "    \n",
    "    print(metrics.confusion_matrix(y, predictions))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produces a classic report metric.\n",
    "# Parameters\n",
    "# model (Model) : The model type.\n",
    "# X_train (Array) : X train data.\n",
    "# y_train (Array) : y train data.\n",
    "# X_valid (Array) : X valid data.\n",
    "# y_valid (Array) : y valid data.\n",
    "# Returns : The classic report metric.\n",
    "def classic_report(model, X_train, y_train, X_valid, y_valid):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predicted = model.predict(X_valid)\n",
    "    \n",
    "    report = classification_report(y_valid, predicted)\n",
    "    \n",
    "    print(report + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
